{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load ML model\n",
    "model = tf.keras.models.load_model('tune model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hand from image\n",
    "def hand_extraction (sourceImage):\n",
    "    # Constants for finding range of skin color in YCrCb\n",
    "    min_YCrCb = np.array([0,133,77],np.uint8)\n",
    "    max_YCrCb = np.array([255,173,127],np.uint8)\n",
    "   \n",
    "    #detect face\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(sourceImage, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        sourceImage = cv2.rectangle(sourceImage,(x,y),(x+w+30,y+h+50),(0,0,0),-1)\n",
    "        roi_gray = sourceImage[y:y+h, x:x+w]\n",
    "        roi_color = sourceImage[y:y+h, x:x+w]\n",
    "        #cv2.imshow(' Output',roi_color)\n",
    "        \n",
    "    # Convert image to YCrCb\n",
    "    imageYCrCb = cv2.cvtColor(sourceImage,cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    # Find region with skin tone in YCrCb image\n",
    "    skinRegion = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
    "    \n",
    "    # Do contour detection on skin region and choosing the one with max area\n",
    "    contours, hierarchy = cv2.findContours(skinRegion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_info=[]\n",
    "    for c in contours:\n",
    "        contour_info.append((\n",
    "            c,\n",
    "            cv2.contourArea(c),\n",
    "        ))\n",
    "    contour_info = sorted(contour_info, key=lambda contour_info:contour_info[1], reverse=True)\n",
    "    max_contour = contour_info[0]\n",
    "\n",
    "    # Draw bounding rectangele for the contour \n",
    "    x,y,w,h = cv2.boundingRect(max_contour[0])\n",
    "    cv2.rectangle(sourceImage, (x, y), (x + w+ 20, y + h + 20), (0, 255,0), 2)\n",
    "    new_img=sourceImage[y:y+h+20,x:x+w+ 20]\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change background to black\n",
    "def background_removal(image):\n",
    "    \n",
    "    #== Parameters =======================================================================\n",
    "    BLUR = 21\n",
    "    CANNY_THRESH_1 = 60\n",
    "    CANNY_THRESH_2 = 120  #100\n",
    "    MASK_DILATE_ITER = 10\n",
    "    MASK_ERODE_ITER = 10\n",
    "    MASK_COLOR = (0.0,0.0,0.0) # In BGR format\n",
    "\n",
    "    #== Processing =======================================================================\n",
    "\n",
    "    # Convert to greyscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #-- Edge detection -------------------------------------------------------------------\n",
    "    edges = cv2.Canny(gray, CANNY_THRESH_1, CANNY_THRESH_2)\n",
    "    edges = cv2.dilate(edges, None)\n",
    "    edges = cv2.erode(edges, None)\n",
    "\n",
    "    #-- Find contours in edges, sort by area ---------------------------------------------\n",
    "    contour_info = []\n",
    "    contours = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[-2]\n",
    "    \n",
    "    for c in contours:\n",
    "        contour_info.append((\n",
    "            c,\n",
    "            cv2.isContourConvex(c),\n",
    "            cv2.contourArea(c),\n",
    "        ))\n",
    "    contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)\n",
    "    # Get contour of max area\n",
    "    max_contour = contour_info[0]\n",
    "\n",
    "    #-- Create empty mask, draw filled polygon on it corresponding to largest contour ----\n",
    "    # Mask is black, polygon is white\n",
    "    mask = np.zeros(edges.shape)\n",
    "    cv2.fillConvexPoly(mask, max_contour[0], (255))\n",
    "\n",
    "    #-- Smooth mask, then blur it --------------------------------------------------------\n",
    "    mask = cv2.dilate(mask, None, iterations=MASK_DILATE_ITER)\n",
    "    mask = cv2.erode(mask, None, iterations=MASK_ERODE_ITER)\n",
    "    mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)\n",
    "    mask_stack = np.dstack([mask]*3)    # Create 3-channel alpha mask\n",
    "\n",
    "    #-- Blend masked img into MASK_COLOR background --------------------------------------\n",
    "    mask_stack  = mask_stack.astype('float32') / 255.0          # Use float matrices,\n",
    "    img         = image.astype('float32') / 255.0                 #  for easy blending\n",
    "\n",
    "    masked = (mask_stack * img) + ((1-mask_stack) * MASK_COLOR) # Blend\n",
    "    masked = (masked * 255).astype('uint8')                     # Convert back to 8-bit\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(temp):\n",
    "###after model  mem b ta thah kaf seen\n",
    "    global n , letter\n",
    "    #get the index of max value in list\n",
    "    m = temp.index(max(temp))\n",
    "    #check the value of index of max\n",
    "    if m==0:\n",
    "        letter = 'م'      #frist index indcate م\n",
    "    elif m==1:\n",
    "        letter = 'ب'     #second index indcate ب\n",
    "    elif m==2:\n",
    "        letter = 'ت'      #third index indcate ت\n",
    "    elif m==3:\n",
    "        letter = 'ث'      #forth index indcate ث\n",
    "    elif m==4:\n",
    "        letter = 'ك'       #fifth index indcate ك\n",
    "    elif m == 5:\n",
    "        letter = 'س'       #sixth index indcate س\n",
    "    \n",
    "    #update the letter \n",
    "    var.set(letter) # name\n",
    "    frame2.update_idletasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera function\n",
    "def cap():\n",
    "    global sentence, img, letter ,word \n",
    "    \n",
    "    # Initialize variables\n",
    "    sentence = \"\"\n",
    "    word = \"\"\n",
    "    \n",
    "    # Start video capture\n",
    "    video = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        \n",
    "        # Read frame\n",
    "        check,frame=video.read()\n",
    "       \n",
    "        # Image processing\n",
    "        # Extract hand from image\n",
    "        crop = hand_extraction(frame)\n",
    "        \n",
    "        # Convert to greyscale\n",
    "        crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #cv2.imshow('frame',crop)\n",
    "        \n",
    "        # Deep learning model\n",
    "        # Resize photo to 64x64 to be same as training data\n",
    "        temp = cv2.resize(crop,dsize=(64,64))\n",
    "        \n",
    "        # Normalize photo\n",
    "        temp = np.array(temp)/255\n",
    "        \n",
    "        # Reshape photo\n",
    "        temp = temp.reshape(1,64,64,1)\n",
    "        \n",
    "        # Pass photo to model\n",
    "        o = model(temp)\n",
    "\n",
    "        # Get letter of highest prediction from model\n",
    "        get_result( [o[0,0], o[0,1], o[0,2], o[0,3], o[0,4], o[0,5] ])\n",
    "        \n",
    "        \n",
    "        # Instructions in camera window\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(gray,'Save letter press \\'a\\'',(60,370), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(gray,'Quit press \\'q\\'',(60,395), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(gray,'Remove the last letter press \\'l\\'',(60,420), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(gray,'Clear word press \\'c\\'',(60,445), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        cv2.putText(gray,'Add word to sentence press \\'space\\'',(60,470), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        # Show camera window\n",
    "        cv2.imshow('Camera', gray)\n",
    "        #cv2.imshow('frame',crop) \n",
    "        frame2.pack()     \n",
    "        \n",
    "        # Get key from user and perform actions\n",
    "        key = cv2.waitKey(1)\n",
    "        \n",
    "        # Quit\n",
    "        if key & 0xFF == ord('q'):\n",
    "            var2.set(word) \n",
    "            var3.set(sentence) \n",
    "            frame2.update_idletasks()\n",
    "            break\n",
    "        \n",
    "        # Add letter\n",
    "        elif key==ord('a'):\n",
    "            word=word+letter\n",
    "            # Update labels with values of variables \n",
    "            var2.set(word) \n",
    "            frame2.update_idletasks()\n",
    "        \n",
    "        # Clear word\n",
    "        elif key ==ord('c'):\n",
    "            word=\"                         \"\n",
    "            var2.set(word)\n",
    "            frame2.update_idletasks()\n",
    "            word=\"\"\n",
    "            # Update labels with values of variables \n",
    "            var2.set(word) \n",
    "            frame2.update_idletasks()\n",
    "        \n",
    "        # Backspace\n",
    "        elif key ==ord('l'):\n",
    "            word= word[:-1]\n",
    "            # Update labels with values of variables \n",
    "            var2.set(word)  \n",
    "            frame2.update_idletasks()\n",
    "        \n",
    "        # Add word to sentence\n",
    "        elif key ==ord(' '):\n",
    "            sentence = sentence + word + ' '\n",
    "            word=\"                          \"\n",
    "            var2.set(word)\n",
    "            frame2.update_idletasks()\n",
    "            word=\"\"\n",
    "            # Update labels with values of variables \n",
    "            var2.set(word) \n",
    "            var3.set(sentence) \n",
    "            frame2.update_idletasks()\n",
    "            \n",
    "    # Close camera window\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion Copy sentence to clipboard\n",
    "def copy_to_clipboard():\n",
    "    global sentence\n",
    "    #clear clipboard\n",
    "    ro.clipboard_clear()\n",
    "    #copy sentence toclipboard\n",
    "    ro.clipboard_append(sentence)\n",
    "    #update the GUI\n",
    "    ro.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"      # outputs the whole sentence\n",
    "letter = ''        # outputs a single char\n",
    "word = \"\"          # outputs a single word\n",
    "\n",
    "ro = Tk()\n",
    "ro.title('capture the images')\n",
    "ro.geometry(\"300x300\")\n",
    "button = Button(ro, text=\"open camera\" ,command=cap , bg = \"gray\" , width = 10  )    # cap command calls the webcam to start capturing\n",
    "button.pack()\n",
    "\n",
    "frame2=Frame(ro, width=250, height=250)     # create a frame with W 250 x H 250\n",
    "\n",
    "# calls copy to    clipboard function which copies the output word to paste it afterwards. \n",
    "\n",
    "button2 = Button(frame2, text=\"copy the word to clipboard\" ,command=copy_to_clipboard , bg = \"gray\" , width = 25  )\n",
    "button2.pack()\n",
    "\n",
    "l1 = Label(frame2, text=\"The Predicted Letter\")\n",
    "var = StringVar()    # create a string variable\n",
    "var.set(letter)      # set it to \"letter\"\n",
    "l2 = Label(frame2, textvariable = var)   # display var \"letter\" as l2 \n",
    "l3 = Label(frame2, text=\"The word\")\n",
    "\n",
    "var2 = StringVar()\n",
    "var2.set(word)        # do the same with \"word\" and store it as a var\n",
    "l4 = Label(frame2, textvariable = var2)   # display it as l4\n",
    "\n",
    "l5 = Label(frame2, text=\"The sentence\")\n",
    "\n",
    "var3 = StringVar()\n",
    "var3.set(sentence)      # do the same with \"sentence\" and store it as a var\n",
    "l6 = Label(frame2, textvariable = var3)   # display it as l6\n",
    "\n",
    "l1.pack()\n",
    "l2.pack()\n",
    "l3.pack()\n",
    "l4.pack()\n",
    "l5.pack()\n",
    "l6.pack()\n",
    "\n",
    "ro.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
